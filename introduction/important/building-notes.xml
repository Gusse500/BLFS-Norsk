<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE sect1 PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
   "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
  <!ENTITY % general-entities SYSTEM "../../general.ent">
  %general-entities;
]>

<sect1 id="unpacking">
  <?dbhtml filename="notes-on-building.html"?>


  <title>Merknader om å Bygge Programvare</title>

  <para>De personene som har bygget et LFS system kan være klar over
  de generelle prinsippene for nedlasting og utpakking av programvare. Noe
  av denne informasjonen gjentas her for de som er nye i byggingen av
  deres egen programvare.</para>

  <para>Hvert sett med installasjonsinstruksjoner inneholder en URL hvor du
  kan laste ned pakken. Oppdateringer; lagres imidlertid på LFS
  servere og er tilgjengelige via HTTP. Disse er referert etter behov i
  installasjonsinstruksjoner.</para>

  <para>Selv om du kan beholde kildefilene hvor som helst du vil, antar vi at
  du har pakket ut pakken og endret til mappen opprettet av
  utpakkingsprosessen (kildemappen). Vi antar også at du har
  dekomprimerte eventuelle nødvendige oppdateringer, og de er i mappen
  rett over kildemappen.</para>

  <para>Vi kan ikke understreke sterkt nok at du bør ta utgangspunkt i et
  <emphasis>rent kildetre</emphasis> hver gang. Dette betyr at hvis
  du har hatt en feil under konfigurasjon eller kompilering, er det vanligvis
  best å slette kildetreet og
  pakke den ut på nytt <emphasis>før</emphasis> du prøver igjen. Dette gjelder åpenbart
  ikke hvis du er en avansert bruker som er vant til å hacke
  <filename>Makefile</filename>er og C kode, men hvis du er i tvil, start fra et
  rent tre.</para>

  <sect2>
    <title>Bygge Programvare som en Uprivilegert (ikke-root) Bruker</title>

    <para>Den gylne regelen for Unix System Administrasjon er å bruke dine
    superkrefter bare når det er nødvendig. Derfor anbefaler BLFS at du
    bygger programvaren som en uprivilegert bruker og bare bli
    <systemitem class='username'>root</systemitem> bruker når du installerer
    programvaren. Denne filosofien følges i alle pakkene i denne boken.
    Med mindre annet er spesifisert, skal alle instruksjoner utføres som en
    uprivilegert bruker. Boken vil gi deg råd om instruksjoner som trenger
    <systemitem class='username'>root</systemitem> privilegier.</para>

  </sect2>

  <sect2>
    <title>Pakke ut Programvaren</title>

    <para>Hvis en fil er i <filename class='extension'>.tar</filename> formatet
    og komprimert, pakkes den ut ved å kjøre en av følgende
    kommandoer:</para>

<screen><userinput>tar -xvf filename.tar.gz
tar -xvf filename.tgz
tar -xvf filename.tar.Z
tar -xvf filename.tar.bz2</userinput></screen>

    <note>
      <para>Du kan utelate å bruke <option>v</option> parameteren i kommandoene
      vist over og under hvis du ønsker å undertrykke den detaljerte listen over alle
      filene i arkivet etter hvert som de pakkes ut. Dette kan bidra til å øke hastigheten
      på utpakkingen samt gjøre eventuelle feil som oppstår under utpakkingen
      mer tydelig for deg.</para>
    </note>

    <para>Du kan også bruke en litt annen metode:</para>

<screen><userinput>bzcat filename.tar.bz2 | tar -xv</userinput></screen>

    <para>
      Til slutt, noen ganger har vi en komprimert oppdateringsfil i
      <filename class='extension'>.patch.gz</filename> eller
      <filename class='extension'>.patch.bz2</filename> formatet.
      Den beste måten å anvende oppdateringen på er å kanalisere utdataen av
      dekomprimeringen til <command>patch</command> verktøyet. For eksempel:
    </para>

    <screen><userinput>gzip -cd ../patchname.patch.gz | patch -p1</userinput></screen>

    <para>
      Eller for en oppdatering komprimert med <command>bzip2</command>:
    </para>

    <screen><userinput>bzcat ../patchname.patch.bz2 | patch -p1</userinput></screen>

  </sect2>

  <sect2>
    <title>Verifiserer Filintegritet</title>

    <para>Generelt, for å bekrefte at den nedlastede filen er fullstendig,
    mange pakkevedlikeholdere distribuerer også md5sum av filene. For å bekrefte
    md5sum av de nedlastede filene, last ned både filen og
    tilsvarende md5sum fil til samme katalog (helst fra en annen
    nettplasseringer), og (forutsatt <filename>file.md5sum</filename> er
    md5sum filen lastet ned) kjør følgende kommando:</para>

<screen><userinput>md5sum -c file.md5sum</userinput></screen>

    <para>Hvis det er noen feil, vil de bli rapportert. Merk at BLFS
    boken også inkluderer md5sum for alle kildefilene. For å bruke BLFS
    medfølgende md5sum, kan du opprette en <filename>file.md5sum</filename> (plasser
    md5sum dataene og det nøyaktige navnet på den nedlastede filen på samme
    linje i en fil, atskilt med mellomrom) og kjør kommandoen vist ovenfor.
    Alternativt kan du bare kjøre kommandoen vist nedenfor og sammenligne utdataene
    til md5sum dataene vist i BLFS boken.</para>

<screen><userinput>md5sum <replaceable>&lt;navn_på_nedlastet_fil&gt;</replaceable></userinput></screen>

    <para>MD5 er ikke kryptografisk sikker, så md5summene er kun
    for å oppdage uønskede endringer i filinnholdet.
    For eksempel en feil eller avkorting som ble introdusert under nettverksoverføring, eller
    en <quote>stealth</quote> oppdatering til pakken fra oppstrøms
    (oppdaterer innholdet i en utgitt tarball i stedet for å lage et nytt
    slipp riktig).</para>

    <para>Det er ingen måte å være <quote>100%</quote> sikker
    på ektheten til kildefilene. Forutsatt at oppstrøms styrer
    nettstedet deres riktig (den private nøkkelen lekkes ikke og domenet ikke er
    kapret), og tillitsankrene er satt opp riktig ved hjelp av
    <xref linkend="make-ca"/> på BLFS systemet kan vi med rimelighet stole på
    nedlastings URL-er til oppstrøms offisielle nettsted
    <emphasis role="bold">med https protokoll</emphasis>.  Noter at
    selve BLFS boken er publisert på en nettside med https, så du bør
    allerede ha litt tillit til https protokollen, ellers ville du ikke stole på
    bokens innhold.</para>

    <para>Hvis pakken er lastet ned fra et uoffisielt sted (for
    eksempel et lokalt speil), kontrollsummer generert av kryptografisk sikre
    sammendragsalgoritmer (for eksempel SHA256) kan brukes til å bekrefte
    ektheten av pakken. Last ned kontrollsumfilen fra oppstrøms
    <emphasis role="bold">offisielle</emphasis> nettsted (eller et sted
    <emphasis role="bold">du kan stole på</emphasis>) og sammenligne
    sjekksummen av pakken fra uoffisiell plassering av den. For eksempel,
    SHA256 sjekksummen kan sjekkes med kommandoen:</para>

    <note>
      <para>Hvis kontrollsummen og pakken er lastet ned fra samme
      uklarerte plassering, vil du ikke oppnå sikkerhetsforbedring ved å bekrefte
      pakken med sjekksummen. Angriperen kan forfalske kontrollsummen
      i tillegg til å kompromittere selve pakken.</para>
    </note>

<screen><userinput>sha256sum -c <replaceable>fil</replaceable>.sha256sum</userinput></screen>

    <para>Hvis <xref linkend="gnupg2"/> er installert, kan du også bekrefte
    ektheten til pakken med en GPG signatur. Importer oppstrøms GPG
    offentlig nøkkel med:</para>

<screen><userinput>gpg --recv-key <replaceable>nøkkelID</replaceable></userinput></screen>

    <para><replaceable>nøkkelID</replaceable> bør erstattes med nøkkelID
    fra et sted <emphasis role="bold">du kan stole på</emphasis> (for
    eksempel, kopier den fra oppstrøms offisielle nettside ved å bruke https). Nå
    kan du verifisere signaturen med:</para>

<screen><userinput>gpg --recv-key <replaceable>fil</replaceable>.sig <replaceable>fil</replaceable></userinput></screen>

    <para>Fordelen med <application>GnuPG</application> signaturen er,
    at når du har importert en offentlig nøkkel som du kan stole på, kan du laste ned
    både pakken og dens signatur fra samme uoffisielle sted og
    verifiser dem med den offentlige nøkkelen. Så du trenger ikke å koble til
    offisielle oppstrømsnettsted for å hente en kontrollsum for hver nye utgivelse.
    Du trenger bare å oppdatere den offentlige nøkkelen hvis den er utløpt eller tilbakekalt.
    </para>

  </sect2>

  <sect2>
    <title>Opprette Loggfiler Under Installasjonen</title>

    <para>For større pakker er det praktisk å lage loggfiler i stedet for
    å stirre på skjermen i håp om å fange en bestemt feil eller advarsel. Loggfiler
    er også nyttige for feilsøking og journalføring. Følgende
    kommando lar deg lage en installasjonslogg. Erstatt
    <replaceable>&lt;kommando&gt;</replaceable> med kommandoen du har tenkt å utføre.</para>

<screen><userinput>( <replaceable>&lt;kommando&gt;</replaceable> 2&gt;&amp;1 | tee compile.log &amp;&amp; exit $PIPESTATUS )</userinput></screen>

    <para><option>2&gt;&amp;1</option> omdirigerer feilmeldinger til den samme
    plassering som standard utdata. <command>tee</command> kommandoen tillater
    visning av utdata mens du logger resultatene til en fil. Parentesene
    rundt kommandoen kjører hele kommandoen i et underskall og til slutt
    <command>exit $PIPESTATUS</command> kommando sikrer resultatet av
    <replaceable>&lt;kommando&gt;</replaceable> returneres som resultatet og ikke
    resultatet av <command>tee</command> kommandoen.</para>

  </sect2>

  <sect2 id="parallel-builds" xreflabel="Using Multiple Processors">
    <title>Bruk av Flere Prosessorer</title>

    <para>For mange moderne systemer med flere prosessorer (eller kjerner) kan
    kompileringstiden for en pakke reduseres ved å utføre en "parallell
    make" ved enten å sette en miljøvariabel eller fortelle make programmet
    å utføre flere jobber samtidig.</para>

    <para>For eksempel inneholder en Intel Core i9-13900K CPU 8 ytelse
    (P) kjerner og 16 effektivitet (E) kjerner, og P-kjernene støtter SMT
    (Simultaneous MultiThreading, også kjent som
    <quote>Hyper-Threading</quote>) slik at hver P-kjerne kan kjøre to tråder
    samtidig og Linux-kjernen vil behandle hver P-kjerne som to
    logiske kjerner.   Som et resultat er det totalt 32 logiske kjerner.
    For å bruke alle disse logiske kjernene som kjører <command>make</command>, vi
    kan sette en miljøvariabel for å fortelle <command>make</command> til å
    kjøre 32 jobber samtidig:</para>

    <screen><userinput>export MAKEFLAGS='-j32'</userinput></screen>

    <para>eller bare bygge med:</para>

     <screen><userinput>make -j32</userinput></screen>

    <para>
      Hvis du har brukt den valgfrie <command>sed</command> når du bygget
      <application>ninja</application> i LFS, kan du bruke:
    </para>

    <screen><userinput>export NINJAJOBS=32</userinput></screen>

    <para>
      når en pakke bruker <command>ninja</command>, eller bare:
    </para>

    <screen><userinput>ninja -j32</userinput></screen>

    <para>
      Hvis du ikke er sikker på antall logiske kjerner, kjør
      <command>nproc</command> kommandoen.
    </para>

    <para>
      For <command>make</command>, standard antall jobber er 1. Men
      for <command>ninja</command>, standard antall jobber er N + 2 hvis
      antallet logiske kjerner N er større enn 2; eller N + 1 hvis
      N er 1 eller 2. Grunnen til å bruke en rekke jobber litt større
      enn antallet logiske kjerner er å holde alle logiske
      prosessorer opptatt selv om noen jobber utfører I/O operasjoner.
    </para>

    <para>
      Merk at <option>-j</option> brytere begrenser bare parallellen
      jobber startet av <command>make</command> eller <command>ninja</command>,
      men hver jobb kan fortsatt skape sine egne prosesser eller tråder.   Til
      eksempel, <command>ld.gold</command> vil bruke flere tråder for
      kobling, og noen tester av pakker kan skape flere tråder for
      testing av trådsikkerhetsegenskaper.   Det er ingen generisk måte for
      byggesystem for å kjenne antall prosesser eller tråder skapt av
      en jobb. Så generelt bør vi ikke vurdere verdien som er gått med
      <option>-j</option> en hard grense for antall logiske kjerner å
      bruke.   Les <xref linkend='build-in-cgroup'/> hvis du vil sette slikt
       en hard grense.
    </para>

    <para>Generelt bør antallet prosesser ikke overstige antallet
    kjerner støttet av CPU. For å liste opp prosessorene på ditt
    system, utsted: <userinput>grep processor /proc/cpuinfo</userinput>.
    </para>

    <para>I noen tilfeller kan bruk av flere prosesser resultere i en "løps"
    tilstand hvor suksessen til bygget avhenger av rekkefølgen til
    kommandoer som kjøres av <command>make</command> programmet. For eksempel, hvis en
    kjørbar trenger fil A og fil B, og prøver å koble programmet før
    en av de avhengige komponentene er tilgjengelig vil resultere i en feil.
    Denne tilstanden oppstår vanligvis fordi oppstrømsutvikleren ikke har
    angitt alle forutsetningene riktig som trengs for å oppnå et trinn i
    Makefile.</para>

    <para>Hvis dette skjer, er den beste måten å fortsette på å gå tilbake til en
    enkelt prosessor bygg. Legg til <option>-j1</option> til en make kommando vil overstyre
    den lignende innstillingen i <envar>MAKEFLAGS</envar>
    miljøvariabel.</para>

    <important>
      <para>
        Et annet problem kan oppstå med moderne CPUer, som har mange kjerner.
        Hver påbegynt jobb bruker minne, og hvis summen av det nødvendige
        minnet for hver jobb overskrider tilgjengelig minne, kan du støte på
        enten et OOM kjerneavbrudd (tom minne) eller intens bruk av  vekselfilen
        som vil bremse byggingen utover rimelige grenser.
      </para>

      <para>
        Noen kompilasjoner med <command>g++</command> kan bruke opptil 2,5 GB
        minne, så for å være sikker bør du begrense antall jobber
        til (Totalt minne i GB)/2,5, i det minste for store pakker som LLVM,
        WebKitGtk, QtWebEngine eller libreoffice.
      </para>
    </important>
  </sect2>

  <sect2 id="build-in-cgroup">
    <title>Bruk Linux Control Group for å begrense ressursbruken</title>

    <para>
      Noen ganger ønsker vi å begrense ressursbruken når vi bygger en
      pakke.   For eksempel, når vi har 8 logiske kjerner, vil vi kanskje
      bruke bare 6 kjerner for å bygge pakken og reservere
      2 kjerner for å spille av en film.   Linux-kjernen har en funksjon
      kalt kontrollgrupper (cgroup) for et slikt behov.
    </para>

    <para>
      Aktiver control group i kjernekonfigurasjonen, og bygg deretter opp igjen
      kjernen og start om nødvendig:
    </para>

    <xi:include xmlns:xi="http://www.w3.org/2001/XInclude"
      href="cgroup-kernel.xml"/>

    <!-- We need cgroup2 mounted at /sys/fs/cgroup.  It's done by
         systemd itself in LFS systemd, mountvirtfs script in LFS sysv. -->

    <para revision='systemd'>
      Forsikre at <xref linkend='systemd'/> og <xref linkend='shadow'/> har
      blitt ombygd med <xref linkend='linux-pam'/> støtte (hvis du
      samhandler via en SSH eller grafisk sesjon, sørg også for
      <xref linkend='openssh'/> serveren eller skrivebordbehandleren er
      bygget med <xref linkend='linux-pam'/>).  som &root; bruker, opprett
      en konfigurasjonsfil for å tillate ressurskontroll uten &root;
      privilegium og instruere <command>systemd</command> å laste
       konfigurasjon på nytt:
    </para>

    <screen revision="systemd" role="nodump"><userinput>mkdir -pv /etc/systemd/system/user@.service.d &amp;&amp;
cat &gt; /etc/systemd/system/user@.service.d/delegate.conf &lt;&lt; EOF &amp;&amp;
<literal>[Service]
Delegate=memory cpuset</literal>
EOF
systemctl daemon-reload</userinput></screen>

    <para revision='systemd'>
      Logg deretter ut og logg på igjen.   Nå for å kjøre <command>make -j5</command>
      med de første 4 logiske kjernene og 8 GB systemminne, utsted:
    </para>

    <screen revision="systemd" role="nodump"><userinput>systemctl   --user start dbus                &amp;&amp;
systemd-run --user --pty --pipe --wait -G -d \
            -p MemoryHigh=8G                 \
            -p AllowedCPUs=0-3               \
            make -j5</userinput></screen>

    <para revision='sysv'>
      Forsikre at <xref linkend='sudo'/> er installert.  For å kjøre
      <command>make -j5</command> med de første 4 logiske kjernene og 8 GB
      av systemminne, utsted:
    </para>

    <!-- "\EOF" because we expect $$ to be expanded by the "bash -e"
         shell, not the current shell.

         TODO: can we use elogind to delegate the controllers (like
         systemd) to avoid relying on sudo?  -->
    <screen revision="sysv" role="nodump"><userinput>bash -e &lt;&lt; \EOF
  sudo mkdir /sys/fs/cgroup/$$
  sudo sh -c \
    "echo +memory +cpuset > /sys/fs/cgroup/cgroup.subtree_control"
  sudo sh -c \
    "echo 0-3 > /sys/fs/cgroup/$$/cpuset.cpus"
  sudo sh -c \
    "echo $(bc -e '8*2^30') > /sys/fs/cgroup/$$/memory.high"
  (
    sudo sh -c "echo $BASHPID > /sys/fs/cgroup/$$/cgroup.procs"
    exec make -j5
  )
  sudo rmdir /sys/fs/cgroup/$$
EOF</userinput></screen>

    <para>
      Med
      <phrase revision='systemd'>
        <parameter>MemoryHigh=8G</parameter>
      </phrase>
      <phrase revision='sysv'>
        <literal>8589934592</literal> (utdataen av
        <userinput>bc -e '8*2^30'</userinput>, 2^30 representerer
        2<superscript>30</superscript>, dvs. en Gigabyte) i
        <filename>memory.high</filename> oppføringen
      </phrase>, en myk grense for minnebruk er satt.
      Hvis prosessene i cgroup (<command>make</command> og alle
      underprosesser av den) bruker mer enn 8 GB systemminne totalt,
      kjernen vil strupe ned prosessene og prøve å gjenvinne
      systemminne fra dem.   Men de kan fortsatt bruke mer enn 8 GB
      systemminne.   Hvis du vil sette en hard grense i stedet, erstatt
      <phrase revision='systemd'>
        <parameter>MemoryHigh</parameter> med
        <parameter>MemoryMax</parameter>.
      </phrase>
      <phrase revision='sysv'>
        <filename>memory.high</filename> med
        <filename>memory.max</filename>.
      </phrase>
      Men å gjøre det vil føre til at prosessene drepes hvis 8 GB ikke er nok
      for dem.
    </para>

    <para>
      <phrase revision='systemd'>
        <parameter>AllowedCPUs=0-3</parameter>
      </phrase>
      <phrase revision='sysv'>
        <literal>0-3</literal> i <filename>cpuset.cpus</filename>
        oppføringen
      </phrase> gjør at kjernen bare kjører prosessene i cgroup på
      de logiske kjernene med tallene 0, 1, 2 eller 3. Det kan hende du må
      juster denne innstillingen basert på kartleggingen mellom de logiske kjernene og
      fysiske kjerner.   For eksempel, med en Intel Core i9-13900K CPU,
      de logiske kjernene 0, 2, 4, ..., 14 er tilordnet de første trådene til
      de åtte fysiske P-kjernene, de logiske kjernene 1, 3, 5, ..., 15 er
      kartlagt til de andre trådene til de fysiske P-kjernene, og den logiske
      kjernene 16, 17, ..., 31 er kartlagt til de 16 fysiske E-kjernene.   Så hvis
      vi ønsker å bruke fire tråder fra fire forskjellige P-kjerner, må vi
      spesifisere <literal>0,2,4,6</literal> i stedet for <literal>0-3</literal>.
      Merk at de andre CPU modeller kan bruke et annet kartleggingsskjema.
      Hvis du ikke er sikker på kartleggingen mellom de logiske kjernene
      og de fysiske kjernene, kjør <command>grep -E '^processor|^core'
      /proc/cpuinfo</command> som vil sende ut logiske kjerne IDer i
      <computeroutput>processor</computeroutput> linjer og fysisk kjerne
      IDer i <computeroutput>core id</computeroutput> linjer.
    </para>

    <para>
      Når <command>nproc</command> eller <command>ninja</command> kommandoer
      kjører i en cgroup, vil den bruke antallet logiske kjerner som er tildelt
      cgroup som <quote>system logical core count.</quote>  For
      eksempel i en cgroup med logiske kjerner 0-3 tildelt,
      <command>nproc</command> vil skrive ut
      <computeroutput>4</computeroutput>, og <command>ninja</command>
      vil kjøre 6 (4 + 2) jobber samtidig hvis ingen <option>-j</option>
      innstilling er eksplisitt gitt.
    </para>

    <para revision="systemd">
      Les manualsidene <ulink role='man'
      url='&man;systemd-run.1'>systemd-run(1)</ulink> og
      <ulink role='man'
  url='&man;systemd.resource-control.5'>systemd.resource-control(5)</ulink>
      for detaljert forklaring av parametere i kommandoen.
    </para>

    <para revision="sysv">
      Les <filename>Documentation/admin-guide/cgroup-v2.rst</filename>
      filen i Linux kjernekildetreet for detaljert forklaring av
      <systemitem class="filesystem">cgroup2</systemitem> pseudo-fil
      systemoppføringer referert til i kommandoen.
    </para>

  </sect2>

  <sect2 id="automating-builds" xreflabel="Automated Building Procedures">
    <title>Automatiserte Byggeprosedyrer</title>

    <para>Det er tider når automatisering av byggingen av en pakke kan være
    praktisk. Alle har sine egne grunner til å ønske å automatisere byggingen,
    og alle gjør det på sin egen måte. Å opprette
    <filename>Makefile</filename>er, <application>Bash</application> skripter,
    <application>Perl</application> skripter eller bare en liste over kommandoer som brukes
    til å klippe og lime er bare noen av metodene du kan bruke for å automatisere
    byggingen av BLFS pakker. Detaljert hvordan og eksempler på de mange
    måter du kan automatisere byggingen av pakker på er utenfor rammen av denne
    seksjonen. Denne delen vil vise deg bruk av filomdirigering og
    <command>yes</command> kommandoer for å gi ideer om hvordan du kan automatisere
    byggene dine.</para>

    <bridgehead renderas="sect3">Filomadressering for å Automatisere Inndata</bridgehead>

    <para>Du vil finne tidspunkter gjennom hele BLFS reisen din at du kommer
    over en pakke som har en kommando som ber deg om informasjon. Denne
    informasjon kan være konfigurasjonsdetaljer, en mappebane eller et svar
    til en lisensavtale. Dette kan by på en utfordring for å automatisere
    byggingen av den pakken. Noen ganger vil du bli bedt om annen
    informasjon i en rekke spørsmål. En metode for å automatisere denne typen
    scenario krever å legge de ønskede svarene i en fil og bruke
    omdirigering slik at programmet bruker dataene i filen som svar på
    spørsmålene.</para>
<!-- outdated
    <para>Å bygge <application>CUPS</application> pakken er et bra
    eksempel på hvordan omdirigering av en fil som inndata til ledetekster kan hjelpe deg med å automatisere
    byggingen. Hvis du kjører testpakken, blir du bedt om å svare på en serie
    spørsmål om hvilken type test som skal kjøres og om du har noen
    hjelpeprogrammer testen kan bruke. Du kan lage en fil med dine
    svar, ett svar per linje, og bruk en kommando som ligner på
    den vist nedenfor for å automatisere kjøringen av testpakken:</para>

<screen><userinput>make check &lt; ../cups-1.1.23-testsuite_parms</userinput></screen>
-->
    <para>Dette gjør effektivt at testpakken bruker svarene i filen
    som innspill til spørsmålene. Av og til kan du ende opp med å gjøre litt
    prøving og feiling for å bestemme det nøyaktige formatet på inndatafilen for noen
    ting, men når du har funnet ut og dokumentert, kan du bruke dette til å automatisere
    byggingen av pakken.</para>

    <bridgehead renderas="sect3">Bruke <command>yes</command> for å Automatisere
    Inndata</bridgehead>

    <para>Noen ganger trenger du bare å gi ett svar, eller gi
    samme svar på mange spørsmål. For disse tilfellene,
    <command>yes</command> kommandoen fungerer veldig bra.
    <command>yes</command> kommandoen kan brukes til å gi et svar (det samme
    ett) til ett eller flere forekomster av spørsmål. Den kan brukes til å simulere
    å trykke på <keycap>Enter</keycap> tasten, skrive inn
    <keycap>Y</keycap> tasten eller skrive inn en tekststreng. Kanskje den enkleste
    måten er å vise bruken på er i et eksempel.</para>

    <para>Først lager du et kort <application>Bash</application> skript ved å
    skrive inn følgende kommandoer:</para>

<screen><userinput>cat &gt; blfs-yes-test1 &lt;&lt; "EOF"
<literal>#!/bin/bash

echo -n -e "\n\nPlease type something (or nothing) and press Enter ---> "

read A_STRING

if test "$A_STRING" = ""; then A_STRING="Just the Enter key was pressed"
else A_STRING="You entered '$A_STRING'"
fi

echo -e "\n\n$A_STRING\n\n"</literal>
EOF
chmod 755 blfs-yes-test1</userinput></screen>

    <para>Kjør nå skriptet ved å utstede <command>./blfs-yes-test1</command> fra
    kommandolinjen. Den vil vente på et svar, som kan være hva som helst (eller
    ingenting) etterfulgt av <keycap>Enter</keycap> tasten. Etter å ha skrevet inn
    noe, vil resultatet bli ekkoet til skjermen. Bruk nå
    <command>yes</command> kommandoen for å automatisere inntasting av en
    respons:</para>

<screen><userinput>yes | ./blfs-yes-test1</userinput></screen>

    <para>Legg merke til videreledingen av <command>yes</command> til skriptet
    resulterer i at <keycap>y</keycap> blir overført til skriptet. Prøv nå med en
    tekststreng:</para>

<screen><userinput>yes 'This is some text' | ./blfs-yes-test1</userinput></screen>

    <para>Den nøyaktige strengen ble brukt som respons på skriptet. Endelig,
    prøv det med en tom (null) streng:</para>

<screen><userinput>yes '' | ./blfs-yes-test1</userinput></screen>

    <para>Legg merke til at dette resulterer i at du bare videreleder pressingen av
    <keycap>Enter</keycap> tasten til skriptet. Dette er nyttig for når
    standardsvar på ledeteksten er tilstrekkelig. Denne syntaksen brukes i
    <xref linkend="net-tools-automate-example"/> instruksjoner for å godta alle
    standardsvarene til de mange ledetekstene under konfigurasjonstrinnet. Du kan nå
    fjerne testskriptet om ønskelig.</para>

    <bridgehead renderas="sect3">Filomadressering for å Automatisere Utdata</bridgehead>

    <para>For å automatisere byggingen av noen pakker, spesielt de
    som krever at du leser en lisensavtale en side om gangen, krever
    å bruke en metode som unngår å måtte trykke på en tast for å vise hver side.
    Omdirigere utdataene til en fil kan brukes i disse tilfellene for å hjelpe
    med automatiseringen. Den forrige delen på denne siden berørte opprettelse
    av loggfiler for byggeutdataen. Omdirigeringsmetoden vist der brukte
    <command>tee</command> kommandoen for å omdirigere utdata til en fil men også
    vise utdataene på skjermen. Her vil utdataen kun sendes til
    en fil.</para>

    <para>Igjen, den enkleste måten å demonstrere teknikken på er å vise et
    eksempel. Usted først kommandoen:</para>

<screen><userinput>ls -l /usr/bin | less</userinput></screen>

    <para>Selvfølgelig må du se utdataene en side om gangen
    fordi <command>less</command> filteret ble brukt. Prøv nå den samme
    kommandoen, men denne gangen omdirigerer utdataene til en fil. Den spesielle filen
    <filename>/dev/null</filename> kan brukes i stedet for filnavnet som vises,
    men du vil ikke ha noen loggfil å undersøke:</para>

<screen><userinput>ls -l /usr/bin | less &gt; redirect_test.log 2&gt;&amp;1</userinput></screen>

    <para>Legg merke til at denne gangen kom kommandoen umiddelbart tilbake til skallets
    ledetekst uten å måtte bla gjennom utdataene. Du kan nå fjerne
    loggfilen.</para>

    <para>Det siste eksemplet vil bruke <command>yes</command>  kommandoen i
    kombinasjon med utdataomdirigering for å omgå å måtte bla gjennom
    utdataen og deretter gi en <keycap>y</keycap> til en spørring. Denne teknikken
    kan brukes i tilfeller der du ellers måtte bla gjennom
    utdata fra en fil (for eksempel en lisensavtale) og svare deretter på
    spørsmål om <computeroutput>do you accept the above?</computeroutput>. 
    For dette eksempelet,
    et annen kort <application>Bash</application> skript kreves:</para>

<screen><userinput>cat &gt; blfs-yes-test2 &lt;&lt; "EOF"
<literal>#!/bin/bash

ls -l /usr/bin | less

echo -n -e "\n\nDid you enjoy reading this? (y,n) "

read A_STRING

if test "$A_STRING" = "y"; then A_STRING="You entered the 'y' key"
else A_STRING="You did NOT enter the 'y' key"
fi

echo -e "\n\n$A_STRING\n\n"</literal>
EOF
chmod 755 blfs-yes-test2</userinput></screen>

    <para>Dette skriptet kan brukes til å simulere et program som krever at du
    leser en lisensavtale, og svarer deretter på riktig måte for å godta
    avtalen før programmet vil installere noe. Kjør først skriptet
    uten automatiseringsteknikker ved å utstede
    <command>./blfs-yes-test2</command>.</para>

    <para>Utfør nå følgende kommando som bruker to automatiseringsteknikker,
    gjøre det egnet for bruk i et automatisert byggeskript:</para>

<screen><userinput>yes | ./blfs-yes-test2 &gt; blfs-yes-test2.log 2&gt;&amp;1</userinput></screen>

    <para>Hvis ønskelig, utsted <command>tail blfs-yes-test2.log</command> for å se
    slutten av den sidesøkte utdataen, og bekreftelse på at <keycap>y</keycap> ble
    sendt videre til skriptet. Når du er overbevist om at den fungerer som den skal,
    kan du fjerne skriptet og loggfilen.</para>

    <para>Til slutt, husk at det er mange måter å automatisere og/eller
    skripte byggekommandoene. Det er ikke en eneste <quote>riktig</quote> måte
    å gjøre det på. Det er bare fantasien din som setter grenser.</para>

  </sect2>

  <sect2>
    <title>Avhengigheter</title>

    <para>For hver pakke som er beskrevet, viser BLFS de kjente avhengighetene.
    Disse er oppført under flere overskrifter, hvis betydning er som følger:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis>Påkrevd</emphasis> betyr at målpakken
        ikke kan bygges riktig uten at avhengigheten først har blitt
        installert, bortsett fra hvis avhengigheten sies å være
        <quote>kjøretid</quote> som betyr at målpakken kan bygges men
        kan ikke fungere uten den.</para>
        <para>
          Merk at en målpakke kan begynne å <quote>fungere</quote>
          på mange subtile måter: en installert konfigurasjonsfil kan gjøre
          init systemet, cron nissen eller buss nissen for å kjøre et program
          automatisk; en annen pakke som bruker målpakken som en
          avhengighet kan kjøre et program fra målpakken i
          byggesystemet; og konfigurasjonsdelene i BLFS boken
          kan også kjøre et program fra en nettopp installert pakke. Så hvis
          du installerer målpakken uten en
          <emphasis>Påkrevd (kjøretid)</emphasis> avhengighet installert,
          Bør du installere avhengigheten så snart som mulig etter
          installasjonen av målpakken.
        </para>
      </listitem>
      <listitem>
        <para><emphasis>Anbefalt</emphasis> betyr at BLFS sterkt
         foreslår at denne pakken installeres først (bortsett fra hvis det sies å være
        <quote>kjøretid,</quote> se nedenfor) for et rent og problemfritt
        bygg, som ikke vil ha problemer verken under byggeprosessen eller ved
        kjøretid. Instruksjonene i boken forutsetter at disse pakkene er
        installert. Noen endringer eller løsninger kan være nødvendige hvis disse
        pakker ikke er installert. Hvis en anbefalt avhengighet er sagt
        å være <quote>kjøretid,</quote> betyr det at BLFS sterkt foreslår
        at denne avhengigheten er installert før du bruker pakken, for
        å få full funksjonalitet.</para>
      </listitem>
      <listitem>
        <para><emphasis>Valgfri</emphasis> betyr at denne pakken kan bli
        installert for ekstra funksjonalitet. Ofte vil BLFS beskrive
        avhengighet for å forklare den ekstra funksjonalitetenen som vil bli resultatet.
        Noen valgfrie avhengigheter kan automatisk plukkes opp av
        målpakken hvis avhengigheten er installert, mens andre
        trenger flere konfigurasjonsalternativer for å bli aktivert
        når målpakken er bygget. Slike tilleggsalternativer er
        ofte dokumentert i BLFS boken. Hvis en valgfri avhengighet er
        sagt å være <quote>kjøretid,</quote> betyr det at du kan installere
        avhengigheten etter installasjon av målpakken for å støtte noen
        valgfrie funksjoner i målpakken hvis du trenger disse
        egenskapene.</para>
        <para>En valgfri avhengighet kan være utenfor BLFS. Hvis du trenger en slik
        <emphasis>ekstern</emphasis> valgfri avhengighet for noen
        funksjoner du trenger, les <xref linkend='beyond'/> for generelle
        hint om å installere en pakke utenfor BLFS.</para>
      </listitem>
    </itemizedlist>

  </sect2>

  <sect2 id="package_updates">
    <title>Bruke de Nyeste Pakkekildene</title>

    <para>Noen ganger kan du støte på en situasjon i boken når en pakke
    ikke vil bygge eller fungere skikkelig. Selv om redaktørene prøver å sikre
    at hver pakke i boken bygger og fungerer som den skal, noen ganger har
    pakken blitt oversett eller ble ikke testet med denne versjonen
    av BLFS.</para>

    <para>Hvis du oppdager at en pakke ikke vil bygge eller fungere som den skal,
    bør du se om det finnes en mer oppdatert versjon av pakken. Typisk betyr
    dette at du går til vedlikeholderens nettsted og laster ned den nyeste
    tarballen og forsøke å bygge pakken. Hvis du ikke kan bestemme
    vedlikeholderens nettsted ved å se på nedlastingsadressene, bruk Google og spør
    etter pakkens navn. Skriv for eksempel i Google-søkefeltet:
    'pakkenavn nedlasting' (utelat anførselstegn) eller noe lignende. Noen ganger
    å skrive: 'pakkenavn hjemmeside' vil resultere i at du finner
    vedlikeholderens nettsted.</para>

  </sect2>

  <sect2 id="stripping">
    <title>Strippe En Gang Til</title>

    <para>
      I LFS, stripping av feilsøkingssymboler og unødvendige symboltabell
      oppføringer ble diskutert et par ganger. Når du bygger BLFS pakker,
      er det generelt ingen spesielle instruksjoner som diskuterer stripping
      en gang til. Stripping kan gjøres mens du installerer en pakke, eller
      etterpå.
    </para>

    <bridgehead renderas="sect3" id="stripping-install">Stripping while Installing a Package</bridgehead>

    <para>
      Det er flere måter å strippe kjørbare filer installert av en
      pakke. Det avhenger av byggesystemet som brukes (se nedenfor <link
        linkend="buildsystems">avsnittet om byggesystemer</link>),
      så bare noen
      generelle forhold kan listes opp her:
    </para>

    <note>
      <para>
        Følgende metoder ved hjelp av funksjonen til et byggesystem
        (autoverktøy, meson eller cmake) vil ikke strippe statiske biblioteker hvis noen
        er installert. Heldigvis er det ikke for mange statiske biblioteker
        i BLFS, og et statisk bibliotek kan alltid strippes trygt med å
        kjøre <command>strip --strip-unneeded</command> på den manuelt.
      </para>
    </note>

    <itemizedlist>
      <listitem>
        <para>
          Pakkene som bruker autoverktøy har vanligvis et
          <parameter>install-strip</parameter> mål i deres genererte
          <filename>Makefile</filename> filer. Så å installere strippede
          kjørbare er bare et spørsmål om å bruke
          <command>make install-strip</command> i stedet for
          <command>make install</command>.
        </para>
      </listitem>
      <listitem>
        <para>
          Pakkene som bruker meson byggesystemet kan godta
          <parameter>-D strip=true</parameter> når du kjører
          <command>meson</command>.  Hvis du har glemt å legge til dette alternativet
          ved kjøring av <command>meson</command>, kan du også kjøre
          <command>meson install --strip</command> i stedet for
          <command>ninja install</command>.
        </para>
      </listitem>
      <listitem>
        <para>
          <command>cmake</command> genererer
          <parameter>install/strip</parameter> mål for både
          <parameter>Unix Makefiles</parameter> og
          <parameter>Ninja</parameter> generatorer (standard er
          <parameter>Unix Makefiles</parameter> på linux). Så bare kjør
          <command>make install/strip</command> eller
          <command>ninja install/strip</command> i stedet for
          <command>install</command> motparter.
        </para>
      </listitem>
      <listitem>
        <para>
          Å strippe (eller ikke generere) feilsøkingssymboler kan også
          oppnås ved å strippe
          <parameter>-g&lt;noe&gt;</parameter> alternativer
          i C/C++ anrop. Hvordan du gjør det er veldig spesifikt for hver enkelt
          pakke. Og den stripper ikke unødvendige symboltabelloppføringer.
          Så det vil ikke bli forklart i detalj her. Se også nedenfor
          avsnittene om optimalisering.
        </para>
      </listitem>
    </itemizedlist>

    <bridgehead renderas="sect3" id="stripping-installed">Stripping av Installerte Kjørbare filer</bridgehead>

    <para>
      <command>strip</command> verktøyet endrer filer på plass, noe som kan
      bryte noe ved å bruke det hvis det er lastet inn i minnet. Merk at hvis en fil er
      i bruk, men nettopp strippet fra disken (dvs. ikke overskrevet eller
      modifisert), er dette ikke et problem siden kjernen kan bruke
      <quote>slettede</quote> filer. Se på <filename>/proc/*/maps</filename>
      og det er sannsynlig at du vil se noen <emphasis>(slettede)</emphasis>
      oppføringer. <command>mv</command> fjerner bare målfilen fra
      mappen, men berører ikke innholdet, slik at den tilfredsstiller
      betingelsen for at kjernen skal bruke den gamle (slettede) filen.
      Men denne tilnærmingen kan løsne harde lenker til dupliserte kopier,
      forårsaker det en oppblåsthet som åpenbart er uønsket når vi stripper for å
      redusere systemstørrelsen. Hvis to filer i samme filsystem deler
      samme inodenummer, de er harde lenker til hverandre, og vi burde
      rekonstruere koblingen. Skriptet nedenfor er bare et eksempel.
      Det skal kjøres som &root; bruker:
    </para>

<screen><userinput>cat &gt; /usr/sbin/strip-all.sh &lt;&lt; "EOF"
<literal>#!/usr/bin/bash

if [ $EUID -ne 0 ]; then
  echo "Need to be root"
  exit 1
fi

last_fs_inode=
last_file=

{ find /usr/lib -type f -name '*.so*' ! -name '*dbg'
  find /usr/lib -type f -name '*.a'
  find /usr/{bin,sbin,libexec} -type f
} | xargs stat -c '%m %i %n' | sort | while read fs inode file; do
       if ! readelf -h $file >/dev/null 2>&amp;1; then continue; fi
       if file $file | grep --quiet --invert-match 'not stripped'; then continue; fi

       if [ "$fs $inode" = "$last_fs_inode" ]; then
         ln -f $last_file $file;
         continue;
       fi

       cp --preserve $file    ${file}.tmp
       strip --strip-unneeded ${file}.tmp
       mv ${file}.tmp $file

       last_fs_inode="$fs $inode"
       last_file=$file
done</literal>
EOF
chmod 744 /usr/sbin/strip-all.sh</userinput></screen>

    <para>
      Hvis du installerer programmer i andre mapper som f.eks <filename
      class="directory">/opt</filename> eller <filename
      class="directory">/usr/local</filename>, kan det være lurt å strippe filene
      der også. Bare legg til andre mapper for å skanne i den sammensatte
      <command>find</command> kommandoen mellom krøllparentesene i listen over.
    </para>

    <para>
      For mer informasjon om stripping, se <ulink
      url="https://www.technovelty.org/linux/stripping-shared-libraries.html"/>.
    </para>

  </sect2>

<!--
  <sect2 id="libtool">
    <title>Libtool files</title>

    <para>
      En av bivirkningene av pakker som bruker Autotools, inkludert
      libtool, er at de lager mange filer med en .la-utvidelse. Disse
      filer er ikke nødvendig i et LFS miljø. Hvis det er konflikter med
      pkgconfig oppføringer, kan de faktisk forhindre vellykkede bygg. Du
      vil kanskje vurdere å fjerne disse filene med jevne mellomrom:
    </para>

<screen><userinput>find /lib /usr/lib -not -path "*Image*" -a -name \*.la -delete</userinput></screen>

    <para>
      Kommandoen ovenfor fjerner alle .la-filer med unntak av de som
      har <quote>Image</quote> eller <quote>openldap</quote> som en del av
      stien. Disse .la-filene brukes av ImageMagick og openldap-programmene,
      hhv. Det kan være andre unntak for pakker som ikke er i BLFS.
    </para>

  </sect2>
-->
  <sect2 id="buildsystems">
    <title>Arbeide med ulike byggesystemer</title>

    <para>
      Det er nå tre forskjellige byggesystemer i vanlig bruk for å
      konvertere C eller C++ kildekode til kompilerte programmer eller
      biblioteker og deres detaljer (spesielt å finne ut om tilgjengelige
      alternativer og deres standardverdier) er forskjellige. Det er kanskje lettest å forstå
      problemene forårsaket av noen valg (vanligvis langsom utførelse eller
      uventet bruk av, eller utelatelse av, optimaliseringer) ved å starte med
      <envar>CFLAGS</envar>, <envar>CXXFLAGS</envar>, og
      <envar>LDFLAGS</envar> miljøvariabler. Det er også noen
      programmer som bruker Rust.
    </para>

    <para>
      De fleste LFS og BLFS byggere er sannsynligvis klar over det grunnleggende om
      <envar>CFLAGS</envar> og <envar>CXXFLAGS</envar> for å endre hvordan et
      program er kompilert. Vanligvis brukes en eller annen form for optimalisering av
      oppstrøms utviklere (<option>-O2</option> eller <option>-O3</option>),
      noen ganger med opprettelse av feilsøkingssymboler (<option>-g</option>),
      som standard.
    </para>

    <para>
      Hvis det er motstridende flagg (f.eks. flere forskjellige
      <option>-O</option> verdier),
      den <emphasis>siste</emphasis> verdien vil bli brukt. Noen ganger betyr dette
      at flagg spesifisert i miljøvariabler vil bli plukket opp før
      verdier hardkodet i Makefilen, og derfor ignorert. For eksempel,
      der en bruker spesifiserer <option>-O2</option> og det blir etterfulgt av
      <option>-O3</option> vil byggingen bruke <option>-O3</option>.
    </para>

    <para>
      Det er forskjellige andre ting som kan sendes i CFLAGS eller
      CXXFLAGS, for eksempel å tillate bruk av instruksjonssettet utvidelser
      tilgjengelig med en spesifikk mikroarkitektur (f.eks.
      <option>-march=amdfam10</option> eller <option>-march=native</option>),
      stille inn den genererte koden for en spesifikk mikroarkitektur (f.eks.
      <option>-mtune=tigerlake</option> or <option>-mtune=native</option>,
      hvis <option>-mtune=</option> ikke brukes, mikroarkitekturen fra
      <option>-march=</option> innstillingen vil bli brukt), eller spesifisere en
      spesifikk standard for C eller C++ (<option>-std=c++17</option> for
      eksempel). Men en ting som nå har kommet frem er at
      programmerere kan inkludere feilsøkingspåstander i koden sin, forventer
      de skal deaktiveres i utgivelser ved å bruke <option>-D NDEBUG</option>.
      Spesielt hvis <xref linkend="mesa"/> er bygget med disse
      påstander aktivert, noen aktiviteter som lasting av spill
      kan ta ekstremt lang tid, selv på skjermkort av høy klasse.
    </para>

    <bridgehead renderas="sect3" id="autotools-info">Autotools med Make</bridgehead>

      <para>
        Denne kombinasjonen beskrives ofte som <quote>CMMI</quote>
        (configure, make, make install) og brukes her til også å dekke
        de få pakkene som har et konfigureringsskript som ikke er
        generert av autoverktøy.
      </para>

      <para>
        Noen ganger å kjøre <command>./configure --help</command> vil produsere
        nyttige alternativer om brytere som kan brukes. Andre ganger,
        etter å ha sett på utdataene fra configure må du kanskje se
        på detaljene i skriptet for å finne ut hva det faktisk søkte
        for.
      </para>

      <para>
       Mange konfigureringsskript vil plukke opp alle CFLAGS eller CXXFLAGS fra
       miljøet, men CMMI pakker varierer med hvordan disse vil bli blandet med
       flagg som ellers ville blitt brukt (<emphasis>forskjellig</emphasis>:
       ignorert, brukt til å erstatte programmererens forslag, brukt før
       programmerers forslag, eller brukt etter programmererens forslag).
      </para>

      <para>
        I de fleste CMMI pakkene vil kjøring av <command>make</command> liste
        hver kommando og kjøre det, ispedd eventuelle advarsler. Men noen
        pakker prøver å være <quote>stille</quote> og bare vise hvilken fil
        de kompilerer eller kobler i stedet for å vise kommandolinjen.
        Hvis du trenger å inspisere kommandoen, enten på grunn av en feil, eller
        bare for å se hvilke alternativer og flagg som brukes, legg til
        <option>V=1</option> for å lage påkallelsen kan hjelpe.
      </para>

    <bridgehead renderas="sect3" id="cmake-info">CMake</bridgehead>

      <para>
        CMake fungerer på en helt annen måte, og den har to bakstykker som kan
        brukes på BLFS: <command>make</command> og
        <command>ninja</command>. Standard bakstykke er make, men
        ninja kan være raskere på store pakker med flere prosessorer. For
        å bruke ninja, spesifiser <option>-G Ninja</option> i cmake kommandoen.
        Imidlertid er det noen pakker som skaper fatale feil i deres
        ninja filer, men bygd vellykket ved å bruke standard Unix
        Makefiler.
      </para>

      <para>
        Den vanskeligste delen med å bruke CMake er å vite hvilke alternativer du måtte ønske
        å spesifisere. Den eneste måten å få en liste over hva pakken vet
        er å kjøre <command>cmake -LAH</command> og se på utdataen for
        standardkonfigurasjon.
      </para>

      <para>
        Det kanskje viktigste med CMake er at den har en variasjon
        av CMAKE_BUILD_TYPE verdier, og disse påvirker flaggene. Standaren
        er at dette ikke er satt og ingen flagg blir generert. Eventuelle
        <envar>CFLAGS</envar> eller <envar>CXXFLAGS</envar>  i miljøet
        vil bli brukt. Hvis programmereren har kodet noen feilsøkingspåstander,
        disse vil være aktivert med mindre -D NDEBUG brukes. Følgende
        CMAKE_BUILD_TYPE verdier vil generere flaggene som vises, og disse
        skal komme <emphasis>etter</emphasis> eventuelle flagg i miljøet
        og har derfor forrang.
      </para>

      <informaltable align="center">
        <tgroup cols="2">
          <colspec colnum="1" align="center"/>
          <colspec colnum="2" align="center"/>
          <thead>
            <row><entry>Verdi</entry><entry>Flagg</entry></row>
          </thead>
          <tbody>
            <row>
              <entry>Debug</entry><entry><option>-g</option></entry>
            </row>
            <row>
              <entry>Release</entry><entry><option>-O3 -D NDEBUG</option></entry>
            </row>
            <row>
              <entry>RelWithDebInfo</entry><entry><option>-O2 -g -D NDEBUG</option></entry>
            </row>
            <row>
              <entry>MinSizeRel</entry><entry><option>-Os -D NDEBUG</option></entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>
        CMake prøver å produsere stille bygginger. For å se detaljene til kommandoene
        som kjøres, bruk <command>make VERBOSE=1</command> eller
        <command>ninja -v</command>.
      </para>

      <para>
        Som standard behandler CMake filinstallasjon annerledes enn andre
        byggesystemer: hvis en fil allerede eksisterer og ikke er nyere enn en fil
        som ville overskrive den, så blir ikke filen installert. Dette kan være
        et problem hvis en bruker ønsker å registrere hvilken fil som tilhører en pakke,
        enten ved hjelp av <envar>LD_PRELOAD</envar>, eller ved å liste nyere filer
        enn et tidsstempel. Standarden kan endres ved å angi variabelen
        <envar>CMAKE_INSTALL_ALWAYS</envar> til 1 i
        <emphasis>miljøet</emphasis>, for eksempel med å
        <command>export</command> det.
      </para>

    <bridgehead renderas="sect3" id="meson-info">Meson</bridgehead>

      <para>
        Meson har noen likheter med CMake, men mange forskjeller. Å få
        detaljer om definisjonene som du kanskje ønsker å endre kan du se på
        <filename>meson_options.txt</filename> som vanligvis er i
         mappen på øverste nivå.
      </para>

      <para>
        Hvis du allerede har konfigurert pakken ved å kjøre
        <command>meson</command> og nå ønsker å endre en eller flere innstillinger,
        kan du enten fjerne byggemappen, gjenskape den og bruke de
        endrede alternativene, eller kjøre i byggemappen <command>meson
        configure</command>, f.eks. for å angi et alternativ:
      </para>

<screen><userinput>meson configure -D &lt;some_option&gt;=true</userinput></screen>

      <para>
        Hvis du gjør det, filen <filename>meson-private/cmd_line.txt</filename>
        vil vise den <emphasis>siste</emphasis> kommandoen som ble brukt.
      </para>

      <para>
        Meson gir følgende byggetype verdier, og flaggene de aktiverer
        kommer <emphasis>etter</emphasis> eventuelle flagg som leveres i miljøet og
        har derfor forrang.
      </para>

      <itemizedlist>
        <listitem>
          <para>plain: ingen flagg lagt til. Dette er for distributører for å levere sine
          egne <envar>CFLAGS</envar>, <envar>CXXFLAGS</envar> og
          <envar>LDFLAGS</envar>. Det er ingen åpenbar grunn til å bruke
          dette i BLFS.</para>
        </listitem>
        <listitem>
          <para>debug: <option>-g</option> - dette er standard hvis
           ingenting er spesifisert i enten <filename>meson.build</filename>
          eller kommandolinjen. Men det resulterer i store og langsomme binærfiler,
          så vi bør overstyre det i BLFS.</para>
        </listitem>
        <listitem>
          <para>debugoptimized: <option>-O2 -g</option> - dette er
          standard spesifisert i <filename>meson.build</filename> av noen
          pakker.</para>
        </listitem>
        <listitem>
          <para>release: <option>-O3</option> (noen ganger vil en pakke
          tvinge <option>-O2</option> her) - dette er byggetypen vi bruker
          for de fleste pakker med Meson byggesystem i BLFS.</para>
        </listitem>
      </itemizedlist>

      <!-- From https://mesonbuild.com/Builtin-options.html#core-options:
           b_ndebug: Default value = false, Possible values are
           true, false, if-release.  Some packages sets it to if-release
           so we mistakenly believed if-release had been the default.  -->
      <para>
        <option>-D NDEBUG</option> flagget antydes av utgivelsen
        byggetype for noen pakker (for eksempel <xref linkend='mesa'/>).
        Det kan også gis eksplisitt ved å sende
        <option>-D b_ndebug=true</option>.
      </para>

      <para>
        For å se detaljene for kommandoene som kjøres i en pakke ved hjelp av
        meson, bruk <command>ninja -v</command>.
      </para>

    <bridgehead renderas="sect3" id="rust-info">Rustc og Cargo</bridgehead>

      <para>
        De fleste utgitte rustc programmer leveres som crates (kilde tarballer)
        som vil spørre en server om å sjekke gjeldende versjoner av avhengigheter
        og last dem ned etter behov. Disse pakkene er bygget med
        <command>cargo --release</command>. I teorien kan du manipulere
        RUSTFLAGS for å endre optimaliseringsnivået (standard for
        <option>--release</option> er 3, dvs
        <option>-Copt-level=3</option>, er lik <option>-O3</option>) eller for å
        tvinge den til å bygge for maskinen den blir kompilert på, ved hjelp av
        <option>-Ctarget-cpu=native</option> men i praksis ser dette ut til å ikke
        gjøre noen vesentlig forskjell.
      </para>

      <para>
        Hvis du kompilerer et frittstående Rust program (som et upakket
        <filename class='extension'>.rs</filename> fil) ved å kjøre
        <command>rustc</command> direkte, bør du spesifisere
        <option>-O</option> (forkortelsen av
        <option>-Copt-level=2</option>) eller <option>-Copt-level=3</option>
        ellers vil den gjøre en uoptimalisert kompilering og kjøre
        <emphasis>mye</emphasis> langsommere. Hvis du kompilerer programmet
        for å feilsøke det, bytt ut <option>-O</option> eller
        <option>-Copt-level=</option> alternativer med <option>-g</option> for å
        produsere et uoptimalisert program med feilsøkingsinformasjon.
      </para>

      <para>
        Lik <command>ninja</command>, som standard <command>cargo</command>
        bruker alle logiske kjerner. Dette kan ofte omgås,
        enten ved å eksportere
        <envar>CARGO_BUILD_JOBS=<replaceable>&lt;N&gt;</replaceable></envar>
        eller sende
        <option>--jobs <replaceable>&lt;N&gt;</replaceable></option> til
        <command>cargo</command>.
        For å kompilere rustc selv, spesifisere
        <option>--jobs <replaceable>&lt;N&gt;</replaceable></option> for
        påkallelser av <command>x.py</command>
        (sammen med <envar>CARGO_BUILD_JOBS</envar> miljøvariabel,
        som ser ut som en <quote>belte og seler</quote>
        tilnærming, men ser ut til å være nødvendig) fungerer for det meste. Unntaket er
        kjører testene når du bygger rustc, noen av dem vil
        bruk likevel alle tilgjengelige CPUer, i det minste fra og med rustc-1.42.0.
      </para>

  </sect2>

  <sect2 id="optimizations">
    <title>Optimalisering av bygget</title>

      <para>
        Mange mennesker vil foretrekke å optimalisere kompileringer slik de finner passende, ved å tilby
        <envar>CFLAGS</envar> eller <envar>CXXFLAGS</envar>. For en
        introduksjon til alternativene tilgjengelig med gcc og g++ se <ulink
        url="https://gcc.gnu.org/onlinedocs/gcc-&gcc-version;/gcc/Optimize-Options.html"/>.
        Det samme innholdet finnes også i <command>info gcc</command>.
      </para>

      <para>
        Noen pakker er som standard <option>-O2 -g</option>, andre
        <option>-O3 -g</option>, og hvis <envar>CFLAGS</envar> eller
        <envar>CXXFLAGS</envar> leveres, kan de legges til
        pakkens standardinnstillinger, erstatte pakkens standardinnstillinger, eller til og med bli
        ignorert. Det er detaljer om noen skrivebordspakker som var
        stort sett aktuelt i april 2019 på
        <ulink url="https://www.linuxfromscratch.org/~ken/tuning/"/> - i
        spesielt, <filename>README.txt</filename>,
        <filename>tuning-1-packages-and-notes.txt</filename>, og
        <filename>tuning-notes-2B.txt</filename>. Det spesielle å
        huske er at hvis du ønsker å prøve noen av de mer interessante
        flagg trenger du kanskje å tvinge detaljerte bygg for å bekrefte hva som blir
        brukt.
      </para>

      <para>
        Klart, hvis du optimaliserer ditt eget program kan du bruke tid på det
        profilere det og kanskje omkode noe av det hvis det er for tregt. Men for
        å bygge et helt system er det upraktisk. Generelt,
        <option>-O3</option> produserer vanligvis raskere programmer enn
        <option>-O2</option>.  Spesifisere
        <option>-march=native</option> er også gunstig, men det betyr
        at du ikke kan flytte binærfilene til en inkompatibel maskin - dette
        gjelder også for nyere maskiner, ikke bare for eldre maskiner. For
        eksempelprogrammer kompilert for <literal>amdfam10</literal> kjører på
        gamle Phenoms, Kaveris og Ryzens, men programmer kompilert for en
        Kaveri vil ikke kjøre på en Ryzen fordi visse op-koder ikke er
        tilstede. På samme måte, hvis du bygger for en Haswell, vil ikke alt
        kjøre på en SandyBridge.
      </para>

      <note>
        <para>
          Pass på at navnet på en <option>-march</option> innstilling
          samsvarer ikke alltid med basislinjen til mikroarkitekturen
          med samme navn. For eksempel Skylake baserte Intel Celeron
          prosessorer støtter ikke AVX i det hele tatt, men
          <option>-march=skylake</option> antar AVX og til og med AVX2.
        </para>
      </note>

      <para>
        Når et delt bibliotek bygges av GCC, en funksjon kalt
        <quote>semantic interposition</quote> er aktivert som standard. Når
        det delte biblioteket refererer til et symbolnavn med ekstern kobling
        og standard synlighet, hvis symbolet finnes i begge de delte
        biblioteket og de viktigste kjørbare, semantiske interposisjonsgarantiene
        symbolet i den kjørbare hovedfilen brukes alltid. Denne funksjonen
        ble oppfunnet i et forsøk på å gjøre oppførselen til å koble til en delt
        bibliotek og koble et statisk bibliotek så likt som mulig. I dag
        bare et lite antall pakker er fortsatt avhengig av semantikk
        interposisjon, men funksjonen er fortsatt på som standard for GCC,
        forårsaker mange optimaliseringer deaktivert for delte biblioteker fordi
        de er i konflikt med semantisk interposisjon.
        <option>-fno-semantic-interposition</option> alternativet kan bli sendt
        til <command>gcc</command> eller <command>g++</command> for å deaktivere
        semantisk interposisjon og muliggjør flere optimaliseringer for delt
        biblioteker. Dette alternativet brukes som standard for enkelte pakker
        (for eksempel <xref linkend='python3'/>), og det er også standard
        for Clang.
      </para>

      <para>
        Det er også forskjellige andre alternativer som noen hevder er
        gunstige. I verste fall får du rekompilere og teste, og så
        oppdage at i din bruk gir alternativene ikke en fordel.
      </para>

      <para>
        Hvis du bygger Perl eller Python moduler,
        generelt <envar>CFLAGS</envar> og <envar>CXXFLAGS</envar>
        brukt er de som ble brukt av disse <quote>foreldre</quote>
        pakker.
      </para>

      <para>
        For <envar>LDFLAGS</envar>, det er tre alternativer som kan brukes
        for optimalisering. De er ganske trygge å bruke og byggesystemet
        for noen pakker bruker noen av disse alternativene som standard.
      </para>

      <para>
        Med <option>-Wl,-O1</option>, linkeren vil
        optimer hash tabellen for å øke hastigheten på den dynamiske koblingen.
        Merk at <option>-Wl,-O1</option> er helt urelatert til
        kompilatoroptimaliseringsflagg <option>-O1</option>.
      </para>

      <para>
        Med <option>-Wl,--as-needed</option>, linkeren vil se bort fra
        unødvendige <option>-l<replaceable>foo</replaceable></option> alternativer
        fra kommandolinjen, dvs. e. det delte biblioteket <systemitem
        class='library'>lib<replaceable>foo</replaceable></systemitem>
        vil bare bli koblet hvis et symbol i <systemitem
        class='library'>lib<replaceable>foo</replaceable></systemitem> er
        virkelig henvist fra det kjørbare eller delte biblioteket som kobles til.
        Dette kan noen ganger dempe <quote>overdreven avhengighet til
        delte biblioteker</quote> problemer forårsaket av
        <application>libtool</application>.
      </para>

      <para>
        Med <option>-Wl,-z,pack-relative-relocs</option>, linkeren
        genererer en mer komprimert form av de relative flytteoppføringene
        for PIE-er og delte biblioteker. Det reduserer størrelsen på den tilknyttede
        PIE eller delt bibliotek, og fremskynder lasting av PIE eller
        delt bibliotek.
      </para>

      <para>
        <option>-Wl,</option> prefiks er nødvendig fordi til tross for at
        variabelen er navngitt <envar>LDFLAGS</envar>, innholdet er faktisk
        sendt til <command>gcc</command> (eller <command>g++</command>,
        <command>clang</command>, etc.) under koblingsstadiet, ikke direkte
        sendt til <command>ld</command>.
      </para>

  </sect2>

  <sect2 id="hardening">
    <title>Alternativer for å sikre bygget</title>

      <para>
        Selv på stasjonære systemer er det fortsatt mye som kan utnytte
        sårbarheter. For mange av disse kommer angrepet via javascript
        i en nettleser. Ofte brukes en rekke sårbarheter for å få
        tilgang til data (eller noen ganger til pwn, dvs. eie, maskinen og
        installer rootkits). De fleste kommersielle distros vil bruke ulike
        sikringstiltak.
      </para>

      <para>
        Tidligere var det Hardened LFS der gcc (en mye eldre versjon)
         ble tvunget til å bruke herding (med alternativer for å slå av noe av det på en
         per pakke-basis). De nåværende LFS- og BLFS-bøkene fører
         videre en del av sin ånd ved å aktivere PIE
        (<option>-fPIE -pie</option>) og SSP
        (<option>-fstack-protector-strong</option>) som standard
        for GCC og clang. Det som dekkes her er annerledes - for det første
        må du forsikre deg om at pakken faktisk bruker flaggene du har lagt til
        og ikke overstyre dem.
      </para>

      <para>
        For herdealternativer som er rimelig billige, finnes det noen
        diskusjon i "tuning" lenken ovenfor (noen ganger kan en eller flere
        av disse alternativene være upassende for en pakke). Disse
        alternativene er <option>-D _FORTIFY_SOURCE=2</option>
        (eller <option>-D _FORTIFY_SOURCE=3</option> som er sikrere men
         med større ytelsesoverhead) og
        (for C++) <option>-D _GLIBCXX_ASSERTIONS</option>. På moderne
        maskiner skal disse bare ha en liten innvirkning på hvor raskt ting
        kjører, og ofte vil de ikke merkes.
      </para>

      <para>
        De viktigste distroene bruker mye mer, for eksempel RELRO (Relocation Read Only)
        og kanskje <option>-fstack-clash-protection</option>. Du kan også
        møte den såkalte <quote>userspace retpoline</quote>
        (<option>-mindirect-branch=thunk</option> etc.) hvilken
        tilsvarer spekter begrensninger som ble tatt i bruk i linuxkjernen
        sent i 2018. Kjernebegrensningene forårsaket mange klager
        om tapt ytelse, hvis du har en produksjonsserver ønsker du kanskje
         å vurdere å teste det, sammen med de andre tilgjengelige alternativene, å
         se om ytelsen fortsatt er tilstrekkelig.
      </para>

      <para>
        Mens gcc har mange herdealternativer, ligger clang/LLVMs styrke
        andre steder. Noen alternativer som gcc tilbyr sies å være mindre effektive
        i clang/LLVM.
      </para>

  </sect2>

</sect1>
